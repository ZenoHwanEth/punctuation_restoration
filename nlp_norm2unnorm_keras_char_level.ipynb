{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nlp norm2unnorm keras char-level.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/unihwan/punctuation_restoration/blob/main/nlp_norm2unnorm_keras_char_level.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oHqt5Vd4o6lx",
        "outputId": "aec788cc-9aa6-4b8e-9752-8a46dbed7615"
      },
      "source": [
        "#for google drive directory (colab)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fi-1C-2u4mmu"
      },
      "source": [
        "#Change your path location here "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCpGakrW4mHY"
      },
      "source": [
        "filepath = \"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kuntkChnpvdp"
      },
      "source": [
        "#Importing library \n",
        "import numpy as np\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, LSTM, Dense,Bidirectional,Activation,dot,concatenate,TimeDistributed\n",
        "from keras.initializers import *\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import math\n",
        "import re\n",
        "import pickle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UFTlk_2j_tb7"
      },
      "source": [
        "# function to get tokenizer\n",
        "def tokenize(lang):\n",
        "    tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='', lower=False, num_words=None, char_level=True)\n",
        "    tokenizer.fit_on_texts(lang)\n",
        "    return tokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AlLgU0lOrwb_"
      },
      "source": [
        "#PREPROCESSING\n",
        "#get line by line from training file\n",
        "with open(filepath + '2008.txt', 'r',encoding='cp1252') as f:\n",
        "    #seperate them line by line\n",
        "    lines = f.read().split('\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLlM_w0er9nF"
      },
      "source": [
        "#initialization\n",
        "# input_texts =  normalized texts\n",
        "# target_texts = unnormalized texts \n",
        "input_texts = []\n",
        "target_texts = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8nVTw-tYsBet"
      },
      "source": [
        "#For each line all the character is lowered\n",
        "#remove punctuation\n",
        "#added \\t and \\n for decoder\n",
        "for line in lines:\n",
        "     input_text = line.lower() #turn line into small capital\n",
        "     input_text = re.sub(r\"[^a-zA-Z0-9]+\", \" \", input_text) #remove punctuation\n",
        "     target_text = '\\t' + line + '\\n' #added \\t for start and \\n indication\n",
        "\n",
        "     #add normalized text into input data and unnormalized data into target data\n",
        "     input_texts.append(input_text) \n",
        "     target_texts.append(target_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4wgxdnQ7UecE"
      },
      "source": [
        "#tokenize input text and put in reverse dic\n",
        "enc_token = tokenize(input_texts)\n",
        "reverse_enc_dict = {i: c for c, i in enc_token.word_index.items()}\n",
        "\n",
        "#tokenize target text and put in reverse dic\n",
        "dec_token = tokenize(target_texts)\n",
        "reverse_dec_dict = {i: c for c, i in dec_token.word_index.items()}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4WEdwg6UsClk"
      },
      "source": [
        "#Number of token add 1 for padding\n",
        "num_encoder_tokens = len(enc_token.word_index)+1\n",
        "num_decoder_tokens = len(dec_token.word_index)+1\n",
        "max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
        "max_decoder_seq_length = max([len(txt) for txt in target_texts])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BI9abxF7sEnh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a7ccd89-a048-4a96-ac4e-05f4386c1ca2"
      },
      "source": [
        "#Print data\n",
        "print('Number of samples:', len(input_texts))\n",
        "print('Number of unique input tokens:', num_encoder_tokens)\n",
        "print('Number of unique output tokens:', num_decoder_tokens)\n",
        "print('Max sequence length for inputs:', max_encoder_seq_length)\n",
        "print('Max sequence length for outputs:', max_decoder_seq_length)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of samples: 562574\n",
            "Number of unique input tokens: 38\n",
            "Number of unique output tokens: 114\n",
            "Max sequence length for inputs: 1428\n",
            "Max sequence length for outputs: 1493\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mzFw1mAPpqJ0",
        "outputId": "e4d3a451-3389-48be-8613-955ac4570102"
      },
      "source": [
        "# save in pickle file\n",
        "save_file = {'max_encoder_seq_length': max_encoder_seq_length,\n",
        "            'max_decoder_seq_length': max_decoder_seq_length,\n",
        "            'num_encoder_tokens': num_encoder_tokens,\n",
        "            'num_decoder_tokens': num_decoder_tokens,\n",
        "            'reverse_enc_dict': reverse_enc_dict,\n",
        "            'reverse_dec_dict': reverse_dec_dict,\n",
        "            'enc_token': enc_token,\n",
        "            'dec_token': dec_token}\n",
        "\n",
        "with open(filepath + 'params_char.pkl', 'wb') as handle:\n",
        "   pickle.dump(save_file, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of samples: 562574\n",
            "All target_characters\n",
            "['\\t', '\\n', ' ', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '<', '=', '>', '?', '@', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', ']', '_', '`', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '~', '\\xa0', '£', '¦', '®', 'º', '»', '¿', 'â', 'é', 'ï', 'ñ', 'ó', 'ô', '–', '—', '‘', '’', '“', '”', '…', '€']\n",
            "All input characters\n",
            "[' ', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
            "Number of unique input tokens: 38\n",
            "Number of unique output tokens: 114\n",
            "Max sequence length for inputs: 1428\n",
            "Max sequence length for outputs: 1493\n",
            "Finished\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iP-Sp7X7RNrR",
        "outputId": "d4ec0cd4-be05-4d29-a771-2a387d06e383"
      },
      "source": [
        "print(input_texts[:10])\n",
        "print(target_texts[:10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['chogm tangani kesan perubahan iklim ', 'kampala uganda 25 nov mesyuarat ketua ketua kerajaan komanwel chogm 2007 yang berakhir hari ini mendesak masyarakat antarabangsa melakukan sesuatu lebih konkrit menangani kesan ancaman perubahan iklim ', 'pada masa yang sama para pemimpin yang hadir mahukan negara maju membantu negara miskin mencapai matlamat pembangunan alaf baru mdg ', 'dua isu ini terkandung dalam dua kenyataan berasingan yang dikeluarkan pada akhir mesyuarat dwi tahunan selama tiga hari itu selain pernyataan bersama secara umum ', 'seramai 35 ketua kerajaan daripada 53 negara anggota komanwel menyertai chogm 2007 yang pada awalnya dibayangi isu penggantungan pakistan sehingga kelihatan menenggelam isu lain ', 'bagaimanapun komitmen negara anggota kali ini lebih matang dimana isu isu semasa turut di beri perhatian secara serius ', 'pada mesyuarat itu pemimpin komanwel mengesahkan komitmen berterusan kepada konvensyen rangka kerja pertubuhan bangsa bangsa bersatu mengenai perubahan iklim unfcc sebagai forum untuk mencapai perjanjian global mengenai tindakan komprehensif secara kolektif ', 'sementara itu dalam pernyataan bersama pemimpin komanwel mengulangi komitmen kepada nilai asas politik iaitu tolak ansur hormat keselamatan dan keamanan antarabangsa ', 'perkara membabitkan demokrasi urus tadbir yang baik hak asasi manusia kesaksamaan gender perundangan kebebasan kehakiman keseimbangan kuasa antara eksekutif pembuat undang undang dan kehakiman serta kebebasan bersuara turut di catat ', 'mereka juga mengalukan usaha berterusan negara anggota untuk memperluaskan bantuan tabung komanwel bagi kerjasama teknikal cftc kepada yang lain termasuk kerjasama selatan selatan ']\n",
            "['\\tCHOGM tangani kesan perubahan iklim \\n', '\\tKAMPALA, Uganda 25 Nov. – Mesyuarat Ketua-Ketua Kerajaan Komanwel (CHOGM) 2007 yang berakhir hari ini, mendesak masyarakat antarabangsa melakukan sesuatu lebih konkrit menangani kesan ancaman perubahan iklim.\\n', '\\tPada masa yang sama, para pemimpin yang hadir mahukan negara maju membantu negara miskin mencapai matlamat pembangunan alaf baru (MDG).\\n', '\\tDua isu ini terkandung dalam dua kenyataan berasingan yang dikeluarkan pada akhir mesyuarat dwi-tahunan selama tiga hari itu selain pernyataan bersama secara umum.\\n', '\\tSeramai 35 ketua kerajaan daripada 53 negara anggota Komanwel menyertai CHOGM 2007 yang pada awalnya dibayangi isu penggantungan Pakistan sehingga kelihatan menenggelam isu lain.\\n', '\\tBagaimanapun komitmen negara anggota kali ini lebih matang dimana isu-isu semasa turut di beri perhatian secara serius.\\n', '\\tPada mesyuarat itu, pemimpin komanwel mengesahkan komitmen berterusan kepada Konvensyen Rangka Kerja Pertubuhan Bangsa-bangsa Bersatu mengenai Perubahan Iklim (UNFCC), sebagai forum untuk mencapai perjanjian global mengenai tindakan komprehensif secara kolektif.\\n', '\\tSementara itu, dalam pernyataan bersama, pemimpin komanwel mengulangi komitmen kepada nilai asas politik iaitu tolak ansur, hormat, keselamatan dan keamanan antarabangsa.\\n', '\\tPerkara membabitkan demokrasi, urus tadbir yang baik; hak asasi manusia; kesaksamaan gender; perundangan; kebebasan kehakiman; keseimbangan kuasa antara eksekutif, pembuat undang-undang dan kehakiman serta kebebasan bersuara turut di catat.\\n', '\\tmereka juga mengalukan usaha berterusan negara anggota untuk memperluaskan bantuan Tabung Komanwel bagi Kerjasama Teknikal (cftc) kepada yang lain termasuk kerjasama selatan-selatan.\\n']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oxZP9CWovyoQ",
        "outputId": "d2fc3dd8-c526-4b44-ee67-49e1b5463ceb"
      },
      "source": [
        "#added line of data from norm.text\n",
        "with open(filepath + 'norm.txt', 'r',encoding='cp1252') as f:\n",
        "  normalize_text_set = f.read().split('\\n')  \n",
        "\n",
        "print(normalize_text_set[:10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['berkoban adalah satu bentuk ujian daripada allah s.w.t', 'kerana dalam menjalani kehidupan di dunia ini kita harus melakukan pengorbanan', 'hidup tanpa pengorbanan adalah kehidupan yang gagal', 'dalam menjalani hidup yang baik kita mesti berkorban masa dan tenaga misalnya berusaha mencari rezeki yang halal bagi mengelakkan kemiskinan', 'a merupakan tuntutan hidup kata pensyarah jabatan dakwah dan pembangunan insan akademi pengajian islam universiti malaya roslan mohamed mengenai konsep berkorban dalam islam', 'korban berasal daripada perkataan arab iaitu udhiyah', 'a menjurus kepada peristiwa pengorbanan satu keluarga iaitu nabi ibrahim dan isterinya hajar yang sanggup mengorbankan sesuatu yang amat mereka sayangi iaitu anaknya nabi ismail demi kasih dan cinta kepada allah s.w.t', 'ini adalah nilai pengorbanan yang cukup tinggi di sisi allah s.w.t', 'kerana ia bukan sahaja menguji kesabaran nabi ibrahim tetapi menduga sejauh mana ketakwaan nabi ibrahim', 'maka allah s.w.t menggantikan tempat nabi ismail dengan seekor biri-biri']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-cgaeDcoyMpN",
        "outputId": "a8d4bbdf-b96e-4732-b3db-e5dc5b021b2b"
      },
      "source": [
        "with open(filepath + 'unnorm.txt', 'r',encoding='cp1252') as f:\n",
        "  unnormalize_text_set = f.read().split('\\n')\n",
        "\n",
        "print(unnormalize_text_set[:10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['\"Berkoban adalah satu bentuk ujian daripada Allah s.w.t. ', 'kerana dalam menjalani kehidupan di dunia ini, kita harus melakukan pengorbanan. ', 'Hidup tanpa pengorbanan adalah kehidupan yang gagal.', 'Dalam menjalani hidup yang baik, kita mesti berkorban masa dan tenaga misalnya berusaha mencari rezeki yang halal bagi mengelakkan kemiskinan. ', 'a merupakan tuntutan hidup,\" kata pensyarah Jabatan Dakwah dan Pembangunan Insan, Akademi Pengajian Islam, Universiti Malaya, Roslan Mohamed mengenai konsep berkorban dalam Islam.', 'Korban berasal daripada perkataan Arab iaitu udhiyah.', 'a menjurus kepada peristiwa pengorbanan satu keluarga iaitu Nabi Ibrahim dan isterinya, Hajar yang sanggup mengorbankan sesuatu yang amat mereka sayangi iaitu anaknya, Nabi Ismail demi kasih dan cinta kepada Allah s.w.t.', '\"Ini adalah nilai pengorbanan yang cukup tinggi di sisi Allah s.w.t. ', 'kerana ia bukan sahaja menguji kesabaran Nabi Ibrahim tetapi menduga sejauh mana ketakwaan Nabi Ibrahim. ', 'Maka Allah s.w.t. menggantikan tempat Nabi Ismail dengan seekor biri-biri.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPgjuydTbEXy"
      },
      "source": [
        "# Load parameters\n",
        "with open(filepath + 'params_char.pkl', \"rb\") as file:\n",
        "    parameters = pickle.load(file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3KRa5ePoe-i"
      },
      "source": [
        "# function to generate input text one-hot sequence\n",
        "# in one hot sequence x-axis indicates unique charater value and y-axis indicates number in sequence\n",
        "def get_text_encodings_generate(texts):\n",
        "    enc_seq = parameters[\"enc_token\"].texts_to_sequences(texts)\n",
        "    pad_seq = pad_sequences(enc_seq, maxlen=parameters[\"max_encoder_seq_length\"],\n",
        "                            padding='post')\n",
        "    pad_seq = to_categorical(pad_seq, num_classes=parameters[\"num_encoder_tokens\"])\n",
        "    return pad_seq"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2V-ns0AoyBi"
      },
      "source": [
        "# function to generate target text one-hot sequence\n",
        "def get_text_decodings_generate(texts):\n",
        "    enc_seq = parameters[\"dec_token\"].texts_to_sequences(texts)\n",
        "    pad_seq = pad_sequences(enc_seq, maxlen=parameters[\"max_decoder_seq_length\"],\n",
        "                            padding='post')\n",
        "    pad_seq = to_categorical(pad_seq, num_classes=parameters[\"num_decoder_tokens\"])\n",
        "  \n",
        "    return pad_seq"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LsjvaUtDlXD9"
      },
      "source": [
        "# function generate batch is to generate small batch size sequence of data in tensor to train\n",
        "# this is because if np.zeros capture all the data from training data which has 562574 lines will cause the RAM to crash\n",
        "def generate_batch(X, y, batch_size=128):\n",
        "    ''' Generate a batch of data '''\n",
        "    while True:\n",
        "        for j in range(0, len(X), batch_size):\n",
        "            \n",
        "            encoder_input_data = np.zeros((batch_size, parameters[\"max_encoder_seq_length\"], parameters[\"num_encoder_tokens\"]), dtype='float32')\n",
        "\n",
        "            decoder_input_data = np.zeros((batch_size, parameters[\"max_decoder_seq_length\"], parameters[\"num_decoder_tokens\"]), dtype='float32')\n",
        "\n",
        "            decoder_target_data = np.zeros((batch_size, parameters[\"max_decoder_seq_length\"], parameters[\"num_decoder_tokens\"]), dtype='float32')\n",
        "\n",
        "            #for each line in tensor will input one hot sequence for encoder_input_data, decoder_input_data and decoder_target_data\n",
        "            for i, (input_text, target_text) in enumerate(zip(X[j:j+batch_size], y[j:j+batch_size])):\n",
        "                \n",
        "                encoder_input_data[i] = get_text_encodings_generate([input_text])\n",
        "                decoder_input_data[i] = get_text_decodings_generate([target_text])\n",
        "                decoder_target_data[i] = get_text_decodings_generate([target_text[1:]])\n",
        "\n",
        "            yield([encoder_input_data, decoder_input_data], decoder_target_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bEuFtfpLIoW"
      },
      "source": [
        "#Generate model for this character-level project\n",
        "encoder_inputs = Input(shape=(None,parameters[\"num_encoder_tokens\"],))\n",
        "encoder = Bidirectional(LSTM(128,return_sequences=True, return_state=True),merge_mode='concat')\n",
        "encoder_outputs, forward_h, forward_c, backward_h, backward_c = encoder(encoder_inputs)\n",
        "\n",
        "encoder_h = concatenate([forward_h, backward_h])\n",
        "encoder_c = concatenate([forward_c, backward_c])\n",
        "\n",
        "decoder_inputs = Input(shape=(None, parameters[\"num_decoder_tokens\"],))\n",
        "decoder_lstm = LSTM(256, return_sequences=True)\n",
        "decoder_outputs = decoder_lstm(decoder_inputs, initial_state=[encoder_h, encoder_c])\n",
        "\n",
        "attention = dot([decoder_outputs, encoder_outputs], axes=(2, 2))\n",
        "attention = Activation('softmax', name='attention')(attention)\n",
        "context = dot([attention, encoder_outputs], axes=(2, 1))\n",
        "decoder_combined_context = concatenate([context, decoder_outputs])\n",
        "\n",
        "output = TimeDistributed(Dense(128, activation=\"relu\"))(decoder_combined_context)\n",
        "output = TimeDistributed(Dense( parameters[\"num_decoder_tokens\"], activation=\"softmax\"))(output)\n",
        "\n",
        "model = Model([encoder_inputs, decoder_inputs], [output])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5bFyKxipBNv8",
        "outputId": "94faf078-6b38-4ae6-d878-a0a5b61e93e9"
      },
      "source": [
        "#print out the structure of the model\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, None, 38)]   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional (Bidirectional)   [(None, None, 256),  171008      input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, None, 114)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 256)          0           bidirectional[0][1]              \n",
            "                                                                 bidirectional[0][3]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 256)          0           bidirectional[0][2]              \n",
            "                                                                 bidirectional[0][4]              \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   (None, None, 256)    379904      input_2[0][0]                    \n",
            "                                                                 concatenate[0][0]                \n",
            "                                                                 concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dot (Dot)                       (None, None, None)   0           lstm_1[0][0]                     \n",
            "                                                                 bidirectional[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "attention (Activation)          (None, None, None)   0           dot[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "dot_1 (Dot)                     (None, None, 256)    0           attention[0][0]                  \n",
            "                                                                 bidirectional[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, None, 512)    0           dot_1[0][0]                      \n",
            "                                                                 lstm_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed (TimeDistribut (None, None, 128)    65664       concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_1 (TimeDistrib (None, None, 114)    14706       time_distributed[0][0]           \n",
            "==================================================================================================\n",
            "Total params: 631,282\n",
            "Trainable params: 631,282\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "hBMXKTlqlkIN",
        "outputId": "d59188db-3a76-419e-80a9-b54f2460cdba"
      },
      "source": [
        "#print out number of line of training data\n",
        "print('input_texts length :' , len(input_texts))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-98b3df4dd112>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#print out number of line of training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'input_texts length :'\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_texts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'input_texts' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWmiipwKpsnb"
      },
      "source": [
        "#function to train model\n",
        "def train_model(batch_size = 128, epochs=5, input_texts=input_texts, target_texts=target_texts):\n",
        "\n",
        "    #set up optimizer, loss function and metric for the model training\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    #start training with training data from input text and target text\n",
        "    #validating the training using validation_data to test with testing data from normalize_text_set (norm.txt) and unnormalize_text_set (unnorm.txt)\n",
        "    model.fit_generator(\n",
        "        generator=generate_batch(X=input_texts, y=target_texts, batch_size=batch_size),\n",
        "        steps_per_epoch=math.ceil(len(input_texts)/batch_size),\n",
        "        epochs=epochs,\n",
        "        verbose=1,\n",
        "        validation_data = generate_batch(X=normalize_text_set, y=unnormalize_text_set, batch_size=batch_size),\n",
        "        validation_steps=math.ceil(len(normalize_text_set)/batch_size),\n",
        "        workers=1,\n",
        "    )\n",
        "\n",
        "    #save the weight from the model\n",
        "    weights_path = os.path.join(filepath, 'checkpoint_char.h5')\n",
        "    model.save_weights(weights_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7rXgGnxszhJN",
        "outputId": "f03a5a70-bddd-4704-c4c5-f9cc94cf1dc8"
      },
      "source": [
        "#train 5 epochs\n",
        "train_model(epochs=5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "4396/4396 [==============================] - 4131s 938ms/step - loss: 0.2480 - accuracy: 0.9406 - val_loss: 0.0305 - val_accuracy: 0.9836\n",
            "Epoch 2/5\n",
            "4396/4396 [==============================] - 4093s 931ms/step - loss: 0.0091 - accuracy: 0.9974 - val_loss: 0.0336 - val_accuracy: 0.9543\n",
            "Epoch 3/5\n",
            "4396/4396 [==============================] - 4086s 929ms/step - loss: 0.0062 - accuracy: 0.9982 - val_loss: 0.0344 - val_accuracy: 0.9918\n",
            "Epoch 4/5\n",
            "4396/4396 [==============================] - 4086s 930ms/step - loss: 0.0047 - accuracy: 0.9986 - val_loss: 0.0359 - val_accuracy: 0.9546\n",
            "Epoch 5/5\n",
            "4396/4396 [==============================] - 4099s 932ms/step - loss: 0.0040 - accuracy: 0.9988 - val_loss: 0.0404 - val_accuracy: 0.9542\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_jBZNbFNa44"
      },
      "source": [
        "#load the weight in the model\n",
        "weights_path = os.path.join(filepath, 'checkpoint_char.h5')\n",
        "model.load_weights(weights_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5CaZUmb523r"
      },
      "source": [
        "#decode the text\n",
        "def decode(model, input_text, batch_size=128):\n",
        "    #process the input data\n",
        "    input_text = input_text.lower() \n",
        "    input_text = re.sub(r\"[^a-zA-Z0-9]\", \" \", input_text)\n",
        "    input_text=re.sub(r'[ ]{2,}',r' ',input_text) \n",
        "\n",
        "    #put the text in a list\n",
        "    input_text_list = [input_text]\n",
        "\n",
        "    #change to encoder input data one hot sequence\n",
        "    input_sequences = get_text_encodings_generate(input_text_list)\n",
        "    parameters[\"reverse_dec_dict\"][0] = \"\\n\"\n",
        "    outputs = [\"\"] * len(input_sequences)\n",
        "\n",
        "    #contruct decoder input data one hot sequence\n",
        "    target_text = \"\\t\"\n",
        "    target_seq = parameters[\"dec_token\"].texts_to_sequences([target_text] * len(input_sequences))\n",
        "    target_seq = pad_sequences(target_seq, maxlen=parameters[\"max_decoder_seq_length\"],\n",
        "                               padding=\"post\")\n",
        "    target_seq_hot = to_categorical(target_seq, num_classes=parameters[\"num_decoder_tokens\"])\n",
        "    \n",
        "    extra_char_count = [0] \n",
        "    i = 0\n",
        "    while True:\n",
        "        curr_char_index = [i - extra_char_count[0]]\n",
        "        input_encodings = np.argmax(input_sequences, axis=2)\n",
        "        cur_inp_list = [input_encodings[0][curr_char_index[0]]]\n",
        "\n",
        "        #predict and change the sequence to words\n",
        "        output_tokens = model.predict([input_sequences, target_seq_hot], batch_size=batch_size)\n",
        "        sampled_possible_indices = np.argsort(output_tokens[:, i, :])[:, ::-1].tolist()\n",
        "        sampled_token_indices = []\n",
        "        for j, per_char_list in enumerate(sampled_possible_indices):\n",
        "            for index in per_char_list:\n",
        "                if parameters[\"reverse_dec_dict\"][index] == '\\n' and cur_inp_list[j] != 0:\n",
        "                    continue\n",
        "                sampled_token_indices.append(index)\n",
        "                break\n",
        "\n",
        "        sampled_chars = [parameters[\"reverse_dec_dict\"][index] for index in sampled_token_indices]\n",
        "        output_text=\"\"\n",
        "        outputs = [outputs[j] + sampled_chars[j] for j, output in enumerate(outputs)]\n",
        "        end_indices = sorted([index for index, char in enumerate(sampled_chars) if char == '\\n'], reverse=True)\n",
        "        \n",
        "        for index in end_indices:\n",
        "            output_text=outputs[index].strip()\n",
        "\n",
        "        #if end_indices has value \n",
        "        if len(end_indices)!=0:\n",
        "            break\n",
        "        target_seq[:, i + 1] = sampled_token_indices\n",
        "        target_seq_hot = to_categorical(target_seq, num_classes=parameters[\"num_decoder_tokens\"])\n",
        "        i += 1\n",
        "    return output_text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WUwCNECeSMUw",
        "outputId": "09ba947b-abfd-4df2-b106-0f2e8d7541c0"
      },
      "source": [
        "print(decode(model, \"dalam kejadian itu muhammad israf izzuddin sembilan belas yang menunggang motosikal dirempuh kereta dipandu lelaki itu yang berlaku pada pukul dua belas tengah malam\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dalam kejadian itu, Muhammad Israf Izzuddin sembilan belas yang menunggang motosikal dirempuh kereta dipandu lelaki itu yang berlaku pada pukul dua belas tengah malam\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "or2uz91h5oSp"
      },
      "source": [
        "with open(filepath + 'testset.txt', 'r',encoding='cp1252') as f:\n",
        "  test_data = f.read().split('\\n')\n",
        "\n",
        "for line in test_data:\n",
        "    print(\"Original Text:\" + line)\n",
        "    line = line.lower() \n",
        "    line = re.sub(r\"[^a-zA-Z0-9]\", \" \", line)\n",
        "    line=re.sub(r'[ ]{2,}',r' ',line) \n",
        "    print(\"Normalized Text:\" + line)\n",
        "    print(\"Predicted Text:\" + decode(model, line))\n",
        "    print()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}